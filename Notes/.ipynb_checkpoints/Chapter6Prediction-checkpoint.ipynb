{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 6 Prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 General Prediction Framework\n",
    "\n",
    "Suppose that we are interested in predicting an <span style=\"color:red\"> outcome, $y$,</span> using a set of features $x_1$, $x_2$, $\\ldots$, $x_p$. In other words, we want to learn a function $f\\left({\\bf x},\\boldsymbol{\\beta}\\right)$ that predics $y$, where the function $f$ us indexed by a vector of parameters $\\boldsymbol{\\beta} \\equiv \\left(\\beta_1,\\ldots, \\beta_p\\right)$. The hope is that, for any new observation $X^*= (x_1^*, x_2^*,\\ldots, x_p^*)^T$, we can predict its outcome $y^*$ with $f(X^*,\\boldsymbol{\\beta})$.  To this end, we need to find the **best** $\\boldsymbol{\\beta}$ for predicting our data. In other words, we search for the vector $\\boldsymbol{\\beta}$ that minimizes $\\mathbb{E}\\left[L\\left(y,  f\\left({\\bf x},\\boldsymbol{\\beta}\\right) \\right)\\right]$, where $L(\\cdot,\\cdot)$ is the loss function or criterion of interest. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can summarize the framework of a general prediction problem as follows. \n",
    "\n",
    "\n",
    "1. Obtain a data set $\\{(y_i,X_i)\\}_{i=1}^n$.\n",
    "2. Choose a criterion $L(y, \\hat{y})$ between the outcome and its predictor.\n",
    "3. Choose a model $\\hat{y}=f(x,\\beta)$ to produce the prediction. \n",
    "4. Find the $\\hat{\\boldsymbol{\\beta}}$ that optimizes the criterion.\n",
    "5. For any given new observations $X^*$, predict its outcome with $f(X,\\hat{\\boldsymbol{\\beta}})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many moving pieces in this framework, in particular, one needs to choose the criterion $L$ and the model $f$. We will visit a few classic examples in this chapter. \n",
    "\n",
    "In general, there are lots of candidate methods for building predictive models. There is no best method **overall**, but there often is a best method **for your data**. There are two keys for a method to do well on your data:\n",
    "    \n",
    "- It does not <span style=\"color:red\"> completely</span> miss important structure\n",
    "- It admits a proper amount of <span style=\"color:blue\"> complexity</span> for the <span style=\"color:blue\"> number of observations</span> in your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example: Hotel booking demand data.** As a motivating example, we consider the Hotel booking demand data from the Kaggle Open Datasets ([link](https://www.kaggle.com/jessemostipak/hotel-booking-demand)). This is a publicly available data set with [many suggestions](https://www.kaggle.com/jessemostipak/hotel-booking-demand/notebooks?datasetId=511638&sortBy=voteCount) on how to analysis it. We consider two questions in this chapter. \n",
    "\n",
    "1. As a customer, predict the average daily rate (`adr`) using available features.\n",
    "2. As a hotel manager, predict the cancellation (`is_canceled`) using available features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Criteria\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 Continuous outcomes\n",
    "\n",
    "With continuous outcome, we often use the squared error, or the $\\ell_2$-norm,  \n",
    "\\[\n",
    "L\\left( y, \\hat{y}\\right) = \\|y-\\hat{y}\\|_2^2\\equiv  \\left( y - \\hat{y}\\right)^2.\n",
    "\\]\n",
    "\n",
    "A famous example that uses this loss function is the least squares estimation for linear regression. In a linear regression, the function $f(X,\\beta)$ takes the form \n",
    "\\[\n",
    "f(X,\\beta)= \\beta_1 x_1 + \\ldots + \\beta_p x_p.  \n",
    "\\]\n",
    "The linear model is usually the place to start for building a predictive model. However, it is rare to have a truly linear relationship between the outcomes and features. The linear form is also very restrictive in modeling. Therefore, the linear model is almost always outperformed by more flexible models. Nevertheless, it is a simply model for us to start exploring predictive modeling. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression in the hotel booking data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.2 Binary outcomes \n",
    "\n",
    "With a binary outcome, we can adapt the squared error loss in the previous section by treating the outcome as $0$ and $1$. Alternatively, we can also take the the <span style=\"color:red\"> likelihood </span> approach. The likelihood for observing $y \\in \\{0,1\\}$ when $y$ is a Bernoulli random variable with probability $p$ is \n",
    "\\[\n",
    "L(y,p)= p^y (1-p)^{1-y}.\n",
    "\\]\n",
    "For a binary outcome $y$, we will often model the probability $y = 1$ as $f(x,\\beta)$, i.e., $p=\\hat{y}=f(x,\\beta)$. In addition, we generally consider the \"log-likelihood\" or the \"negative-log-likelihood\". These lead us to the negative-log-likelihood\n",
    "\\[\n",
    "L\\big( y,f(x,\\beta)\\big) = - y \\cdot \\log\\left(\\frac{ f(x,\\beta)}{1-f(x,\\beta) }\\right) + \\log\\big(1- f(x,\\beta) \\big).\n",
    "\\]\n",
    "\n",
    "It is slightly more traditional to model $g(x,\\beta) = \\log\\left(\\frac{f(x,\\beta)}{1-f(x,\\beta)}\\right)$, since $g(x,\\beta)$ takes values in the whole real line while $f(x,\\beta)$ is restricted to live in $[0,1]$. For instance, we can assume that $g(x,\\beta)= \\beta_1 x_1 + \\ldots + \\beta_p x_p.$ This is equivalent to \n",
    "\\[\n",
    "    f(x) = \\frac{e^{x_1\\beta_1 + \\ldots + x_p\\beta_p}}{1+ e^{x_1\\beta_1 + \\ldots + x_p\\beta_p}},\n",
    "\\]\n",
    "which is known as the <span style=\"color:blue\"> logistic</span> regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic regression for cancellation\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 6.2.3 Categorical outcome\n",
    "\n",
    "If we observe categorical outcome, i.e., $y\\in\\{1,\\ldots, K\\}$. We can generalize the idea in the previous section by considering $K$ functions $f_1,\\ldots, f_k$  and set the probabilty of $y = j$ as $f_j(x)/\\sum_{k=1}^K f_k(x)$. \n",
    "\n",
    "We thus have the negative-log-likelihood\n",
    "\\[\n",
    "L( y,  f_1(x),\\ldots, f_K(x)) = -\\log\\left( f_{ y } (x)\\right) + \\operatorname{log}\\left(\\sum_{k=1}^K  f_k(x)\\right)\n",
    "\\]\n",
    "In this case, it is more traditional to model $g(x) = \\log(f(x))$ which lives in the whole real line. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 6.3 Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3.1 Meta-feature generation\n",
    "\t\n",
    "We can create a nonlinear model with even only one single feature $x$. \n",
    "\n",
    "- <span style=\"color:red\">Local smoothing:</span> For each $x$-value, estimate outcome with an average of observations with nearby $x$-values.\n",
    "\n",
    "- <span style=\"color:blue\"> Meta-feature construction:</span> Rather than just using $x$ as our one feature, we use e.g. $x, x^2, \\ldots, x^5$ as features; and then set he model to be \n",
    "\\[\n",
    "    f(x,\\beta) =\\beta_1 x + \\beta_2 x^2 + \\ldots + \\beta_5 x^5\n",
    "\\]\n",
    "This is like doing  multiple regression  on $5$ features, where all 5 features are generated by the one $x$. \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "For <span style=\"color:red\">local smoothing</span> we now need a **distance** or **kernel** for multivariate ${\\bf x}$ \n",
    "\t\n",
    "Often use Euclidean distance:\n",
    "\t\\[\n",
    "\tD\\big[\\underbrace{\\left( x_{1},x_{2} \\right)}_{\\textrm{observation $1$}}, \\underbrace{\\left( x_{1},x_{2} \\right)}_{\\textrm{observation $2$}}\\big] \\equiv \\sqrt{\\left( x_{1} - x_{1} \\right)^2 + \\left( x_{2}  -  x_{2} \\right)^2}.\n",
    "\t\\]\n",
    "The Euclidean distance is equivalent to a Gaussian kernel with equal variance. We can also include weights or choosing different kernels for interesting data-types.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For continuous features various expansions may be used:\n",
    "\n",
    "- Polynomial basis\n",
    "\\[\n",
    "\t\t\\begin{pmatrix} \\,\\\\x\\\\ \\, \\end{pmatrix}\n",
    "\t\t\\rightarrow\n",
    "\t\t\\begin{pmatrix}\n",
    "\t\t\\, & \\, & \\, & \\, \\\\ x, & x^2, & \\cdots, &  x^m\\\\ \\, & \\, & \\, & \\,\n",
    "\t\t\\end{pmatrix}\n",
    "\\]\n",
    "        \n",
    "- Spline basis\n",
    "\\[\n",
    "\t\t\\begin{pmatrix} \\,\\\\x\\\\ \\, \\end{pmatrix}\n",
    "\t\t\\rightarrow\n",
    "\t\t\\begin{pmatrix}\n",
    "\t\t\\, & \\, & \\, & \\, \\\\  x, &  \\left(x - t_1\\right)_{+}, & \\cdots, & \\left(x - t_m\\right)_{+}\\\\ \\, & \\, & \\, & \\,\n",
    "\t\t\\end{pmatrix}\n",
    "\\]\n",
    "\n",
    "- Others include higher order spline, Fourier, wavelet, among others.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Same ideas can be employed with multiple features: \n",
    "\n",
    "- Additive: e.g. $( x_1 , x_2 ) \\rightarrow ( x_1,x_1^2,x_1^3, x_2,x_2^2,x_2^3)$\n",
    "- Interacting: e.g. $( x_1 ,x_2 ) \\rightarrow ( x_1,x_1^2 ,  x_2,x_2^2 , x_1 x_2 ,  x_1^2 x_2  , x_1 x_2^2 )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of smoothing in R\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\t\n",
    "<figure>\n",
    "  <img src=\"../Figures/Ch6/sin.png\" alt=\"sin()\" style=\"width:70%\">\n",
    "  <figcaption> </figcaption>\n",
    "</figure>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 6.3.2 Tree-Based Methods\n",
    "\n",
    "The tree-based method (e.g., random forest) is a popular approach for building predictive models. A tree is likely an over-simplification of the true relationship. However, it is very easy to interpret, and has a nice graphical representation: you can easily explain it to a non-statistician, and do not need a computer (or even a calculator) to get an estimate!\n",
    "\n",
    "The general steps for building a regression (or classification) tree is quite simple:\n",
    "\n",
    "- **stratify** (or segment) the predictor space, i.e. the set of possible values for $X_1, X_2, \\ldots, X_p$, into {\\color{red} $J$ distinct and non-overlapping regions}, $R_1, R_2, \\ldots, R_J$.\n",
    "\n",
    "- Use the mean (regression) or mode (classification) of the response values for the training observations in region $R_j$ as the predicted response for that region.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   The main questions in this procedure are: <span style=\"color:red\"> how should we construct the regions</span> $R_1, \\ldots, R_J$, and <span style=\"color:red\"> how many regions should we use</span>? \n",
    "\n",
    "\n",
    "Suppose $J$ is known. How to construct the regions $R_1, \\ldots, R_J$?\n",
    "- Divide the predictor space into high-dimensional <span style=\"color:red\"> rectangles</span> or boxes (in theory any shape can be used, but this is simpler)\n",
    "- Find boxes $R_1, \\ldots, R_J$ that minimize the residual sum of squares\n",
    "\\[\n",
    "L(y, \\hat{y})=\\sum_{j=1}^J \\sum_{i \\in R_j} (y_i - {\\hat{y}_{R_j}})^2. \n",
    "\\]\n",
    "We can see that the criterion for a (regression) tree still takes the squared error form. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it is not possible to consider every possible partition of the space into $J$ boxes. We consider instead a *greedy* approach called <span style=\"color:blue\"> recursive binary splitting</span>.  We take a top-down approach that is similar to hierarchical clustering. The best split is determined at each given step, instead of the best global step. In particular, at each step we do the following.                            \n",
    "- For every $j=1,\\ldots, p$, we choose  <span style=\"color:red\">cut point</span> $t_j$ such that splitting the predictor space into regions\n",
    "\\[\n",
    " R_1(j, t_j) = \\{ X \\mid X_j < t_j\\}, \\ \\ \\  R_2(j, t) = \\{ X \\mid X_j \\ge t_j\\}.\n",
    "\\]\n",
    "Here the $t_j$ is chosen as \n",
    "\\[\n",
    "\\underset{t}{\\arg\\min} \\sum_{i: x_i \\in R_1(j,t)} (y_i - \\hat{y}_{R_1})^2 + \\sum_{i: x_i \\in R_2(j,t)} (y_i - \\hat{y}_{R_2})^2\n",
    "\\]\n",
    "- We find the value of $j$ with the smallest residual sum of squares \n",
    "\\[\n",
    "\\sum_{i: x_i \\in R_1(j,t_j)} (y_i - \\hat{y}_{R_1})^2 + \\sum_{i: x_i \\in R_2(j,t_j)} (y_i - \\hat{y}_{R_2})^2. \n",
    "\\]\n",
    "\n",
    "We will repeat the above process to split a subspace (rather than the whole space) in each step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Extensions of Trees **\n",
    "\n",
    "We have considered the squared error loss. Similarly, trees can extend naturally to binary/survival data choose splits greedily to minimize loss.                          \n",
    "                                                    \n",
    "Trees are often used as <span style=\"color:blue\"> base learners</span>\n",
    "<span style=\"color:red\"> model aggregation/ensembling</span>, e.g. boosting, bagging, stacking. \n",
    "\n",
    "Some `R` functions are better equipped to deal with high dimensional data ($p> n$) than others. Rarely will it hurt your method to prescreen out features that are extremely marginally uncorrelated with outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##---------------------------------------##\n",
    "## Decistion tree ####\n",
    "### \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Model selection\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.1 Overview \n",
    "\n",
    "Model selection has many meanings. \n",
    "\n",
    "- It can mean selecting features and how they are to be included in the model. This is known as feature selection, and sometimes feature generation. \n",
    "- It can mean selecting the tuning parameters in e.g., penalized regression, decision trees, deep learning. This is also known as <span style=\"color:blue\"> tuning parameter selection</span>\n",
    " - It can mean choosing between a range of models, for instance, regression tree (random forest), neural network (deep learning), or logistic regression. \n",
    " \n",
    "Recall that we have identified the criterion for deciding the \"best\" model. It is natural to wonder why not just pick the one model that minimizes that criterion. There are two important questions to address here. \n",
    "\n",
    "1. On what data to evaluate the criterion.\n",
    "2. How to evaluate the criterion in a computational feasible way.\n",
    "\n",
    "\n",
    "The first question is particular important. If the answer is to evaluate the criterion based on same data set, a phenomenon known as **overfitting** is inevitable. The game for model selection is essentially to avoid overfitting. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.2 Resctricting model complexity\n",
    "\n",
    "Roughly speaking, the complexity of a model is tantamount to the number of parameters in the model. A model with more parameters is more flexible for learning the unknown mechanism, but at the same time may be sensitive to random patterns that are unique to this observed data set. A solution is to restrict the model complexity by penalizing the number of parameters. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2.1 Information criteria\n",
    "\n",
    "The criterion in Section 6.2 places no constraint on the number of parameters. A classic strategy for avoiding overfitting is to supplement the loss function with a penalty on the **number of parameters**. Two very famous examples are the Akaike information criterion and the Bayesian information criterion. \n",
    "\n",
    "- Akaike information criterion (AIC): ${\\rm AIC}=2k - \\log (\\hat{L}_k)$ where $k$ is the number of parameters and $\\hat{L}_k$ is the loss function with $k$ parameters. \n",
    "\n",
    "- Bayesian information criterion (BIC): ${\\rm BIC}=k\\log(n) - \\log (\\hat{L}_k)$ where $k$ is the number of parameters and $\\hat{L}_k$ is the loss function with $k$ parameters. \n",
    "\n",
    "The only difference between AIC and BIC is in the weights of $k$. In AIC, the weight is a constant 2, while in BIC the weight is $\\log(n)$ that increases as the sample size increases. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2.2 Penalization or regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to restricting the number of parameters, we can also restrict the range of the parameters. This can be done by placing penalties on the magnitudes of the parameters. Two popular choices are the $\\ell_1$-norm and $\\ell_2$-norm on the parameters. \n",
    "\n",
    "- $\\ell_1$-norm (lasso): $P(\\beta_1,\\ldots,\\beta_p) = |\\beta_1| + \\ldots + |\\beta_p|.$\n",
    "\n",
    "- $\\ell_1$-norm (ridge, Tikhonov): $P(\\beta_1,\\ldots,\\beta_p) = \\beta_1^2 + \\ldots + \\beta_p^2.$\n",
    "\n",
    "We then choose $\\beta_0,\\beta_1,\\ldots, \\beta_k$, to minimize\n",
    "\t\\[\n",
    "\t \\left[L\\left( y,  {\\beta_0 + \\beta_1 x_1 + ... +\\beta_k x_k}\\right)\\right] + \\lambda P\\left(\\beta_1,\\ldots,\\beta_k\\right),\n",
    "\t\\]\n",
    "where $\\lambda$ modulates the degree of penalization. In other words, increasing $\\lambda$ reults in a less complex model.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example with lasso and ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.4.2.3 Tree Pruning\n",
    "\n",
    "\n",
    " Complexity of the regression tree is determined by the number of regions $J$\n",
    "\n",
    "- A tree with large $J$ may work well in training data, but would be very bad on test data\n",
    "- A smaller tree with fewer splits might have lower variance and better interpretation at the cost of a little bias\n",
    "- One option is to consider a split only if the drop in residual sum of squares is larger than some (high) threshold\n",
    "- However, this may not be a good strategy since a so-so split at step $j$ may be followed by a great one at step $j+1$\n",
    "- Instead, we <span style=\"color:blue\"> first grow a large tree</span>, e.g. until no region has $>5$ observations, and then <span style=\"color:red\"> prune</span> it to obtain a <span style=\"color:red\"> subtree</span>\n",
    "- And, again, we (basically) use <span style=\"color:red\"> cross validation</span> to select $J$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prune a tree, we can use cross-validation, however, it will be too computationally expensive to estimate the CV error for every possible subtree. Instead we use a strategy called <span style=\"color:red\"> cost complexity pruning</span> a.k.a. <span style=\"color:red\"> weakest link pruning</span>. \n",
    "\n",
    "Rather than considering every possible subtree, we consider a sequence of trees indexed by a nonnegative tuning parameter $\\alpha$. For each value of $\\alpha$, there exists a subtree $T \\subset T_0$ such that \n",
    "\\[\n",
    "\\sum_{k=1}^{|T|}\\sum_{x_i \\in R_k} (y_i - \\hat{y}_{R_k})^2 + \\alpha |T|\n",
    "\\]\n",
    " is as small as possible ($|T|$ is the number of leaves of the tree). \n",
    " \n",
    " Here  $\\alpha$ controls the tradeoff between complexity and fit and we can select $\\alpha$ using validation set or CV approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of tree pruning:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Split-sample validation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than constraining the complexity, we can directly deal with overfitting. The issue of overfitting is when the model over fits the random patterns in the data set, where these patterns will not be seen in the new observations. A straight-forward way to address this issue is to employ **independent Validation**. That is, the chosen criterion will be evaluated on an independent testing set, where the model is trained on a training set. \n",
    "\n",
    "In practice, we may not be able to collect a new set of data from the same population using the same sampling scheme. However, we can create the training-test sets from one data set. We can *randomly* split the data set into two sets, where $q\\%$ of the data belong to the training set and $(1-q)\\%$ the test set. When the split is random, it is reasonable to believe that the two sets share the same data generating mechanism. The split needs some careful thoughts when there are structures in the data (e.g., time series data). \n",
    "\n",
    "After splitting the data set into training set and test set, we can explore any models in the training set, and to evaluate their performance in the test data. \n",
    "\n",
    "\n",
    "Split sample validation protects against over-optimism due to fishing through hypotheses on the training data. However, split Sample Validation does not necessarily give a great estimate of performance \"in the wild\". For instance, \n",
    "- If all samples were run in one lab, your data cannot say how well things generalize to other labs\\\\\n",
    "- Effects found in a subpopulation defined by one criteria may not reproduce if the subpopulation is defined by a different (but nominally similar) criteria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example** Split Sample Validation - Lasso\n",
    "\n",
    "For choosing $\\lambda$ in the lasso...\n",
    "- Split your data into a <span style=\"color:blue\"> training</span> set and a <span style=\"color:orange\"> validation</span> set\n",
    "- Choose candidate $\\lambda$-values ($\\lambda_1,\\ldots,\\lambda_m$)\n",
    "- For each candidate $\\lambda$-value, fit your Lasso model on the <span style=\"color:blue\"> training</span> data to get a set of coefficients\\\\\n",
    "- Evaluate each of the $m$ sets of coefficients on your <span style=\"color:orange\"> validation</span> data.\n",
    "\n",
    "<span style=\"color:red\"> Final Step):</span> Refit the Lasso model to **all the data**, using the best $\\lambda$-value. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "More Generally\n",
    "\n",
    "Suppose we are deciding between a <span style=\"color:blue\"> neural network </span>, a <span style=\"color:red\"> regression tree with depth $3$</span>, and a <span style=\"color:orange\"> regression tree with depth $5$</span>.\\\\\n",
    "- Split your data into a training set and a validation set\n",
    "- For each of our $3$ procedures, build a predictive model on the training data\n",
    "- Evaluate each of the $3$ predictive models on the validation data.\n",
    "\n",
    "<span style=\"color:red\"> Final Step:</span> Refit a predictive model to the full data, using the **best** procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split-sample validation \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4.3 Cross-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The split-sample validation does not seem an efficient use of the data set. Only part of the data is used in training the model, and the other part produces estimates of the criterion with low precision due to limited sample size. \n",
    "\n",
    "How about \"rotating\" the roles of training and validation? For instance, we can split the data equally into two sets. We train the model on Set 1 and evaluate the fitted model on Set 2. Then, we train the model on Set 2 and evaluate the fitted model on Set 1. This way, all data are used at least once in fitting a model, and once in evaluating the model fitted from other data. In both cases, overfitting is curbed since training and validation happen on independent data sets. This procedure is known as **cross-validation**.\n",
    "\n",
    "In general, the $K$-fold cross-validation works as follows. We randomly partition our data into $K$ non-overlapping sets, a.k.a. folds. Suppose that there are $K$ folds. Each time, we then use $1$ fold as the test set, and all $K-1$ folds as the training set. After iterating through all $K$ folds, we use the average criterion (e.g., loss function) from the $K$ iterations as the final performance measure of the procedure. We will pick the procedure with the best performance and refit the procedure on the full data set. \n",
    "\n",
    "A special case of cross-validation is the leave-one-out validation, where 1 observation is left out as the test set each time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
